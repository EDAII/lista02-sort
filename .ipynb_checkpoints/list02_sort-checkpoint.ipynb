{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "NUMBER_OF_ELEMENTS = 100\n",
    "RANGE_OF_ELEMENTS = 100000\n",
    "\n",
    "def generate_random_numbers():\n",
    "     return random.sample(range(RANGE_OF_ELEMENTS), NUMBER_OF_ELEMENTS)\n",
    "\n",
    "list_number = generate_random_numbers()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sequential_sort(list_number):\n",
    "    size_list = len(list_number)\n",
    "    for i in range(0,size_list):\n",
    "        current = list_number[i]\n",
    "        min_value =  min(list_number[i:])\n",
    "        min_value_index = list_number.index(min(list_number[i:]))\n",
    "        if current != min_value :\n",
    "            list_number[i], list_number[min_value_index] = list_number[min_value_index] , list_number[i]\n",
    "    return list_number\n",
    "\n",
    "list_number = sequential_sort(list_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_for_frame = [[]]\n",
    "result = []\n",
    "for i in range(0,500000):\n",
    "    lis_number = generate_random_numbers()\n",
    "    flag = random.randint(1,RANGE_OF_ELEMENTS)\n",
    "    if flag % 3 == 0:\n",
    "        lis_number.sort()\n",
    "        result.append('True')\n",
    "    else :\n",
    "        result.append('False')\n",
    "        \n",
    "    list_for_frame.append(lis_number[0:20])\n",
    "df = pd.DataFrame(list_for_frame,columns=['Elem :1','Elem :2','Elem :3','Elem :4','Elem :5','Elem :6','Elem :7',\n",
    "                        'Elem :8','Elem :9','Elem :10','Elem :11','Elem :12','Elem :13','Elem :14',\n",
    "                      'Elem :15','Elem :16','Elem :17','Elem :18','Elem :19','Elem :20'])\n",
    "\n",
    "df = df.drop(df.index[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_pandas_series = pd.Series(result)\n",
    "df['Result'] = list_pandas_series.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_target_frame(frame, target_column):\n",
    "    df_mod = frame.copy()\n",
    "    targets = df_mod[target_column].unique()\n",
    "    map_to_int = {name: n for n, name in enumerate(targets)}\n",
    "    df_mod[\"Target\"] = df_mod[target_column].map({'True':1, 'False':0})\n",
    "    return (df_mod, targets)\n",
    "frame, targets = make_target_frame(df, \"Result\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "columns = list(frame.columns[0:20])\n",
    "\n",
    "y = frame[\"Result\"]\n",
    "x = frame[columns]\n",
    "tree = DecisionTreeClassifier()\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "tree.fit(X_train,y_train)\n",
    "predictions = tree.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acurácia\n",
    "\n",
    "Afim de saber a capacidade do sistema de concluir de forma correta a classificação dos dados.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9998787878787879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, precision_score, recall_score, hamming_loss\n",
    "print(accuracy_score(y_test,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(109886, 15, 5, 55094)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test, predictions).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<b>tn</b> = Representa a quantidade de result = false, que foram acertados corretamente pelo modelo.<br/>\n",
    "<b>fp</b> = Representa a quantidade de result = true, que foram errados pelo modelo.<br/>\n",
    "<b>fn</b> = Representa a quantidade de result = false, que foram errados pelo modelo.<br/>\n",
    "<b>tp</b> = Representa a quantidade de result = true, que foram acertados corretamente pelo modelo.<br/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
